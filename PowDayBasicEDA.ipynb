{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ace667-e7f2-4659-b06c-036347f657ee",
   "metadata": {},
   "source": [
    "# EDA - Lift Opening Times\n",
    "Start Date: 2021.10.25<br>\n",
    "William Matthews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f9178-07dd-4c35-82ec-cc9ffeb96dc0",
   "metadata": {},
   "source": [
    "### Report Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818d170-4406-46ef-8fdb-36170ecb981e",
   "metadata": {},
   "source": [
    "This report has two primary purposes.  The first is to load up our cleaned dataset from PowDay and confirm that our data cleaning process accomplished what we wanted.  The second is to complete EDA and a time-series analylsis to determine the following:\n",
    "- The balance of our target data set\n",
    "- Basic insights into our target data set\n",
    "- Determine if our time series is stationary or not and transform as needed\n",
    "- Explore autocorrelation for lifts within a season and across seasons\n",
    "- Explore partial autocorrelation for lifts within a season and across seasons\n",
    "- Calculate sample entropy to determine how hard of a problem we have signed up for\n",
    "- Perform Granger Causality test to determine if any one lift is useful in predicting if another lift will open."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b22acc-5f6c-419d-9150-b5f26bf66d87",
   "metadata": {},
   "source": [
    "### Load and Confirm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72417934-df69-4a2b-a5ad-db1a58f81ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for data management\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98be7e6e-3a30-4ea4-a32e-f088c84da516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "lift_df = pd.read_csv('./Data/PowDayHistoryClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15f5b769-9906-43c6-b0ee-425f1b5017bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26264 entries, 0 to 26263\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   time        26264 non-null  object\n",
      " 1   lift        26264 non-null  object\n",
      " 2   day_status  26264 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 615.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26264, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lift</th>\n",
       "      <th>day_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>Whistler Village Gondola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>Jersey Cream</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>7th Heaven</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>Glacier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time                      lift  day_status\n",
       "0  2014-12-31 00:00:00  Whistler Village Gondola           0\n",
       "1  2014-12-31 00:00:00              Jersey Cream           0\n",
       "2  2014-12-31 00:00:00                   Crystal           0\n",
       "3  2014-12-31 00:00:00                7th Heaven           0\n",
       "4  2014-12-31 00:00:00                   Glacier           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first looks\n",
    "display(lift_df.shape, lift_df.head(), lift_df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c6a84-2d56-499f-a255-066fe38f7002",
   "metadata": {},
   "source": [
    "The number of rows and columns match the last check before creating the csv file, so that is great!  It looks like `time` needs to be transformed back into a `datetime` object.  Let's do that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "105bda0f-265f-4f6e-a17e-36ff6a92e183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26264 entries, 0 to 26263\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   time        26264 non-null  datetime64[ns]\n",
      " 1   lift        26264 non-null  object        \n",
      " 2   day_status  26264 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 615.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# transform to datetime object\n",
    "lift_df['time'] = pd.to_datetime(lift_df['time'])\n",
    "\n",
    "# confirm it worked\n",
    "lift_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8322d6-5e84-4670-a49f-794d663b7b0a",
   "metadata": {},
   "source": [
    "Our above transformation worked.  Let's use that to confrim our starting and ending dates for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6c6f334-2d73-4c00-a137-e6bc16ede57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min   2014-12-31 00:00:00\n",
       "max   2021-03-29 10:30:14\n",
       "Name: time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_df['time'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea8b5e-d8c3-4a17-b8fe-abccd53e2f0f",
   "metadata": {},
   "source": [
    "The above dates match what we expected to see, that our data set ranges from the last day of 2014 through the end of the 2020/2021 season.\n",
    "\n",
    "It looks like our data is all as we expected, so let's move onto EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f743b0-75c4-43b3-88ec-18186657af2e",
   "metadata": {},
   "source": [
    "### EDA - Determining Balance of Target Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2491a4b8-cbd1-4220-bebb-13022f0c6013",
   "metadata": {},
   "source": [
    "The goal of the model is to predict if a given lift will open on a given day.  The user of the output is going to be interested in both cases being predicted accurately.  That means  the only metric of real interest to us is the accuracy of the model.  We are going to establish a baseline on which this accuracy will be judged by calculating the average probabililty that a lift is open/closed on any given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffccc6cf-4787-49ea-b586-e8ea960b33dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Closed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lift</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Emerald</th>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red Chair</th>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.037313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whistler Village Gondola (Lower)</th>\n",
       "      <td>0.957356</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creekside Gondola</th>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.044776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whistler Village Gondola</th>\n",
       "      <td>0.954158</td>\n",
       "      <td>0.045842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jersey Cream</th>\n",
       "      <td>0.943497</td>\n",
       "      <td>0.056503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excalibur Gondola (Lower)</th>\n",
       "      <td>0.938166</td>\n",
       "      <td>0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excelerator</th>\n",
       "      <td>0.938166</td>\n",
       "      <td>0.061834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excalibur Gondola</th>\n",
       "      <td>0.934968</td>\n",
       "      <td>0.065032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catskinner</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blackcomb Gondola (Lower)</th>\n",
       "      <td>0.912580</td>\n",
       "      <td>0.087420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blackcomb Gondola</th>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.088486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peak 2 Peak</th>\n",
       "      <td>0.899787</td>\n",
       "      <td>0.100213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garbanzo</th>\n",
       "      <td>0.893390</td>\n",
       "      <td>0.106610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olympic</th>\n",
       "      <td>0.877399</td>\n",
       "      <td>0.122601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crystal</th>\n",
       "      <td>0.861407</td>\n",
       "      <td>0.138593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fitzsimmons</th>\n",
       "      <td>0.817697</td>\n",
       "      <td>0.182303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th Heaven</th>\n",
       "      <td>0.780384</td>\n",
       "      <td>0.219616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glacier</th>\n",
       "      <td>0.777186</td>\n",
       "      <td>0.222814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harmony</th>\n",
       "      <td>0.763326</td>\n",
       "      <td>0.236674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peak</th>\n",
       "      <td>0.759062</td>\n",
       "      <td>0.240938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanky's Ladder</th>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.262260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Showcase</th>\n",
       "      <td>0.689765</td>\n",
       "      <td>0.310235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symphony</th>\n",
       "      <td>0.672708</td>\n",
       "      <td>0.327292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blackcomb Glacier</th>\n",
       "      <td>0.670576</td>\n",
       "      <td>0.329424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-BAR</th>\n",
       "      <td>0.654584</td>\n",
       "      <td>0.345416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flute Bowl</th>\n",
       "      <td>0.613006</td>\n",
       "      <td>0.386994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franz's</th>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Open    Closed\n",
       "lift                                                \n",
       "Emerald                           0.962687  0.037313\n",
       "Red Chair                         0.962687  0.037313\n",
       "Whistler Village Gondola (Lower)  0.957356  0.042644\n",
       "Creekside Gondola                 0.955224  0.044776\n",
       "Whistler Village Gondola          0.954158  0.045842\n",
       "Jersey Cream                      0.943497  0.056503\n",
       "Excalibur Gondola (Lower)         0.938166  0.061834\n",
       "Excelerator                       0.938166  0.061834\n",
       "Excalibur Gondola                 0.934968  0.065032\n",
       "Catskinner                        0.928571  0.071429\n",
       "Blackcomb Gondola (Lower)         0.912580  0.087420\n",
       "Blackcomb Gondola                 0.911514  0.088486\n",
       "Peak 2 Peak                       0.899787  0.100213\n",
       "Garbanzo                          0.893390  0.106610\n",
       "Olympic                           0.877399  0.122601\n",
       "Crystal                           0.861407  0.138593\n",
       "Fitzsimmons                       0.817697  0.182303\n",
       "7th Heaven                        0.780384  0.219616\n",
       "Glacier                           0.777186  0.222814\n",
       "Harmony                           0.763326  0.236674\n",
       "Peak                              0.759062  0.240938\n",
       "Spanky's Ladder                   0.737740  0.262260\n",
       "Showcase                          0.689765  0.310235\n",
       "Symphony                          0.672708  0.327292\n",
       "Blackcomb Glacier                 0.670576  0.329424\n",
       "T-BAR                             0.654584  0.345416\n",
       "Flute Bowl                        0.613006  0.386994\n",
       "Franz's                           0.164179  0.835821"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by chair and get average of open/closed days\n",
    "mean_prob_df = lift_df.groupby('lift').mean()[['day_status']]\n",
    "\n",
    "# rename day_status column for readability\n",
    "mean_prob_df.rename(columns={'day_status': 'Open'}, inplace = True)\n",
    "\n",
    "# create inverse probability\n",
    "mean_prob_df['Closed'] = (1 - mean_prob_df['Open'])\n",
    "\n",
    "# check it worked and rank by Open\n",
    "mean_prob_df.sort_values('Open', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4092f714-1a1b-44a9-9aac-bdbccf913f57",
   "metadata": {},
   "source": [
    "The above looks like we expected based on our experience skiing Whistler/Blackcomb.  From it we can draw the following insights:\n",
    "- For the mountain access gondolas and the mid-mountain lifts, the threashold for providing accurate predictions is incrediably high.  If we cannot nail a near 100% accuracy in predictions for these lifts, we will not be providing any information of value.\n",
    "- The alpline lifts (`7th Heaven, Glacier, Harmony, Peak, Symphony`) are the primary lifts of interest for prediction purposes.  As a group they are open between 67% to 78% of the time.  That is a much more manageable target.  We will have to be careful in the modelling stage though, as it is always better to have equally balanced data sets.\n",
    "- `Franz's` lift is a mid-mountain lift with openings/closings that have been a complete mystery to just about everyone.  Most people don't even understand why it was built.  There is a chance we may drop it from our target set if it's openings/closing are to difficult to predict.  This would not be an issue as no one ever really rides it!\n",
    "- The 'ski areas' in our list each have an opening probability lower than the lifts that service them (`Glacier/Spanky's, Showcase/Blackcomb Glacier, Symphony/Flute Bowl`) as expected.\n",
    "- `Symphony` has a lower opening frequency than `Harmony` as expected.  `Harmony` is the access route to `Symphony`.  This means the probability of `Harmony` opening should be part of the predictor set used to determine if `Symphony` will open.\n",
    "- `Emerald` and `Red Chair` have the highest opening percentages.  This might seem counter intuitive since they are mid-mountain lifts and you need the mountain access gondolas to be open in order to access them.  The key is that when at least one of `Whistler Village Gondola` or `Creekside Gondola`, but not neccessarily both, are open you are able to access `Emerald` and `Red Chair`.  The conclusion we can draw from `Emerald` and `Red Chair` having higher opening percentages is that they are more reliable (just) from a mechanical standpoint.\n",
    "\n",
    "To summarize, when we get to the modelling stage, we will have to use additional techniques to ensure the imbalance in our target data does not adversely affect our model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd86b07-c0a0-47c3-9a88-6a6f9b059a46",
   "metadata": {},
   "source": [
    "### EDA - Basic Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542f7ba-1e0d-49b6-a2fb-1992b7a23f7d",
   "metadata": {},
   "source": [
    "Let's start taking a look a our data on a season-by-seaons basis.  First thing to do is define our seasons.  Stealing from our data cleaning session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0071ea4-a755-4684-af6e-5c8aff442bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store tuples of (open, close)\n",
    "seasons = []\n",
    "\n",
    "# add all open close dates\n",
    "seasons.append((datetime.datetime(2014, 12, 31), datetime.datetime(2015, 4, 17, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2015, 11, 19), datetime.datetime(2016, 4, 17, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2016, 11, 23), datetime.datetime(2017, 4, 17, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2017, 11, 17), datetime.datetime(2018, 4, 17, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2018, 11, 22), datetime.datetime(2019, 4, 17, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2019, 11, 26), datetime.datetime(2020, 3, 14, 23, 59, 59)))\n",
    "seasons.append((datetime.datetime(2020, 11, 26), datetime.datetime(2021, 3, 29, 23, 59, 59)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c23df5-6efd-4082-93cd-c4e5d87e848c",
   "metadata": {},
   "source": [
    "Let's get a look at the open/closed frequencies for each chair by season."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454d5b3-8be9-4ddf-8f97-753df1d7db2d",
   "metadata": {},
   "source": [
    "# Left Off Here - Log 1.5 hrs to this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3fbd3bb3-21d2-4bbc-b0d1-baf692316d3a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def open_closed_lift_days(df, open_close):\n",
    "    \"\"\"\n",
    "    Takes a current data frame of lift records and a list of season dates. Returns how many\n",
    "    days open and closed for each chair lift in each season.\n",
    "    _________________\n",
    "    \n",
    "    Parameters:\n",
    "                df: pandas dataFrame object, columns[time, lift, day_status]\n",
    "                open_close: a list of 2-tuples storing datetime objects in the form (opening day, closing day)\n",
    "    ________________\n",
    "    \n",
    "    Returns:\n",
    "           pandas dataframe object with lifts as rows, seasons as columns with sub columns for \n",
    "           open/closed,  and days open/closed as values \n",
    "    \n",
    "    \"\"\"    \n",
    "    # dict to store {lift: dict{season: days_missed}\n",
    "    lift_dict = {}\n",
    "    \n",
    "    # for each chair\n",
    "    for lift in df['lift'].unique():\n",
    "        \n",
    "        # dict to store {season: open_closed_dict}\n",
    "        season_dict = {}\n",
    "        \n",
    "        # for each season - utilize season dates stored earlier\n",
    "        for opened, closed in open_close:\n",
    "            \n",
    "            # dict to store {open: num_day_open, closed: num_days closed}\n",
    "            open_closed_dict = {}\n",
    "            \n",
    "#             # extract days from time delta object\n",
    "#             days_in_season = (closed - opened).days + 1\n",
    "\n",
    "#             # extract number of records\n",
    "#             season_records = df[(df['lift'] == lift) & \n",
    "#                                 (df['time'] >= opened) & \n",
    "#                                 (df['time'] <= closed)].shape[0]\n",
    "\n",
    "            # calculate days with out records in the season and store\n",
    "            missing_days = days_in_season - season_records\n",
    "            season_label = f\"{opened.year}/{closed.year}\"\n",
    "            season_dict[season_label] = missing_days\n",
    "            #print(f\"{lift} in {opened.year}/{closed.year} missing {days_in_season - season_records} days\")\n",
    "        lift_dict[lift] = season_dict\n",
    "    \n",
    "    # create and return dataFrame\n",
    "    df = pd.DataFrame(data = lift_dict).T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffd7e4-3eb4-4e4c-af0e-085f3672ec70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e34b569-7157-41e7-a627-991cc8e69534",
   "metadata": {},
   "source": [
    "Next let's see if there are any major patterns in a given lifts opening/closing frequency. (do heat map for each chair by season)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
